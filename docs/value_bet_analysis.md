# value_bet戦略の的中率・回収率低下の原因分析

## 概要

`value_bet`戦略に「モデルタイプに関係なくレース内線形正規化を適用」する変更を加えた結果、`top1_tansho`（予測1位の単勝をそのまま購入）よりも的中率・回収率ともに低下した。本レポートでは原因を分析する。

---

## 1. 根本原因：P(top3) を P(win) として扱っている

**これが最大の問題。**

現在のモデル（`model_meta.json: objective=binary`）は「3着以内確率 P(top3)」を予測する二値分類モデルである。`_linear_normalize_group()`はこの出力をレース内で合計1.0に正規化し、あたかも「1着確率 P(win)」であるかのように扱っている。

しかし **P(top3) と P(win) は本質的に異なる確率分布** であり、この変換は理論的に正しくない。

### 具体例

| 馬 | P(top3) 生出力 | 正規化後 | 実際のP(win) | 単勝オッズ |
|----|-------------|---------|------------|----------|
| A（本命） | 0.75 | 0.375 | 0.35 | 2.5 |
| B（対抗） | 0.60 | 0.225 | 0.20 | 4.0 |
| C（穴馬） | 0.40 | 0.100 | 0.15 | 8.0 |
| D | 0.25 | 0.050 | 0.05 | 15.0 |

- **馬B:** 正規化後の「確率」は0.225、オッズ4.0 → EV = 0.90 < 1.0 → **購入しない**
- しかし実際のP(win)=0.20、EV = 0.20 × 4.0 = 0.80 → 確かに購入しないのが正しいかもしれない

問題はもっと根本的で、**P(top3)の比率がP(win)の比率と一致する保証がない**ということ。2着・3着に来やすいが1着にはなりにくい「善戦マン」タイプの馬は、P(top3)が高くても正規化後の確率はP(win)を過大評価する。逆に、飛ぶか勝つかの「一発屋」タイプは過小評価される。

### なぜtop1_tanshoでは問題にならないか

`top1_tansho`は単純に「予測確率が最も高い馬を1頭買う」戦略。P(top3)の**順位**だけを使い、**確率値そのもの**は使わない。順位であればP(top3)とP(win)は高い相関があるため、概ね正しく機能する。

一方`value_bet`は `確率値 × オッズ >= 1.0` という閾値判定を行うため、確率値の**絶対的なキャリブレーション**が正確でないと機能しない。

---

## 2. 線形正規化（min-shift）の数学的問題

```python
shifted = scores - scores.min()
total = shifted.sum()
return shifted / total
```

この正規化には複数の問題がある。

### 2-1. 最下位馬の確率が常に0になる

`scores.min()` を引くため、レース内で最も低いスコアの馬は必ず正規化後の確率が0になる。しかし現実にはどの馬にも勝つ可能性がある（大穴馬が勝つケースは年間何度もある）。確率0の馬が勝った場合、その馬は絶対にvalue_betの対象にならないため、大穴的中を完全に取りこぼす。

### 2-2. スコア分布への依存

線形正規化は、元のスコアの分布形状に強く依存する。

- **1強レース（1頭だけ突出）:** 1頭に確率が集中し、他の馬の確率は極端に小さくなる。実際には2番手以下にも相当な勝率があるのに、購入対象から外れる。
- **混戦レース（全馬接戦）:** 各馬の確率差が小さくなり、本来高確率の馬でもオッズとの積が1.0を超えにくくなる。

### 2-3. 二値分類の出力（sigmoid確率）に対する不適切な変換

LightGBMの二値分類はsigmoid関数を通した出力（0〜1の確率）を返す。これは既にキャリブレーションされた確率であり、レース内の合計は約3.0（3着以内が3頭なので）程度になるのが自然。

min-shiftしてから合計1.0に正規化すると、元のキャリブレーション情報が完全に失われる。特に、全体的に確率が低い（荒れそうな）レースと、全体的に確率が高い（堅いレース）の区別がつかなくなる。

---

## 3. ベット数の膨張による回収率悪化

### 3-1. 単勝ベットの増加

`top1_tansho`は1レース1点（100円）固定。一方`value_bet`は `EV >= 1.0` を満たす**全馬**の単勝を購入する。正規化確率が過大評価された馬を大量に購入するため、「当たらない馬券」が増えて回収率が薄まる。

### 3-2. 馬連ベットの追加

該当馬が2頭以上のレースでは、全組み合わせの馬連も追加購入する。

- 3頭該当: 単勝3点 + 馬連3点 = 6点（600円）
- 4頭該当: 単勝4点 + 馬連6点 = 10点（1000円）

馬連はそもそも「2頭とも3着以内」ではなく「2頭が1着・2着」を当てる必要があり、P(top3)ベースの確率ではさらに精度が落ちる。

### 3-3. 投資効率の悪化メカニズム

| 指標 | top1_tansho | value_bet |
|------|-----------|-----------|
| 1レースあたりベット数 | 1点固定 | 可変（1〜10+点） |
| ベット単価 | 100円 | 100円 × N点 |
| 的中時の回収 | 単勝配当のみ | 単勝 + 馬連（当たれば） |
| 「ハズレ馬券」の比率 | 低い | 高い |

top1_tanshoは「最も確信度の高い1頭に集中投資」するため、的中率が最大化される。value_betは確率の閾値で「薄く広く」張るため、1点あたりの期待精度が下がる。

---

## 4. 確定オッズの使用（データリーク問題）

`_get_odds_from_db()`は`n_odds_tanpuku`テーブルから確定オッズを取得している。CLAUDE.mdにも記載の通り、このテーブルにはDataKubunがなく最新（＝確定）データで上書きされるため、**シミュレーション時に未来の情報（確定オッズ）を使って期待値計算している**ことになる。

これは一見有利に働くはずだが、実際にはさらに悪い方向に作用しうる。

- 確定オッズは最終的な市場の合意であり、概ね真の勝率に近い
- 正規化後の「確率」が真のP(win)からズレているとき、確定オッズとの積は**ノイズの多い期待値**になる
- 「確率が過大評価された馬 × 適正オッズ ≧ 1.0」→ 実際はEV < 1.0 の馬を買ってしまう

---

## 5. 改善案

### 案A: P(win)モデルを使う（推奨）

`--target win`で1着予測モデルを学習し、value_betにはそのモデルの出力を使う。P(win)を直接予測するため、正規化不要でキャリブレーションも正確になる。

```bash
python run_train.py --target win --model-name win_model --force-rebuild
```

### 案B: 正規化をsoftmaxに変更

線形正規化の代わりにsoftmax正規化を使う。sigmoidの出力にはsoftmaxのほうが理論的に整合性がある。

```python
def _softmax_normalize_group(scores: pd.Series) -> pd.Series:
    exp_scores = np.exp(scores - scores.max())  # オーバーフロー防止
    return exp_scores / exp_scores.sum()
```

ただし、これでもP(top3)→P(win)の変換としては不正確。

### 案C: 正規化ではなく生出力を使い、閾値を調整

二値分類の生出力は「3着以内確率」なので、`P(top3) / 3` を大雑把なP(win)の近似として使う。

```python
approx_p_win = raw_pred / race_sum  # race_sum ≈ 3.0
ev = approx_p_win * odds
```

### 案D: Plattスケーリングで確率をキャリブレーション

モデル出力のキャリブレーションを検証データで補正し、より正確な確率値を得る。

### 案E: 閾値の引き上げ

EV ≧ 1.0 の閾値を 1.3〜1.5 に引き上げ、確信度の高い馬のみ購入することでノイズを減らす。

---

## まとめ

| 原因 | 影響度 | 説明 |
|------|--------|------|
| P(top3)をP(win)として使用 | **大** | 確率の意味が根本的に異なり、期待値計算が破綻 |
| 線形正規化の歪み | **大** | 最下位=0、キャリブレーション喪失 |
| ベット数の膨張 | **中** | 精度の低い馬券が増え回収率が薄まる |
| 確定オッズのリーク | **小〜中** | 本来有利なはずが、確率の歪みで逆効果 |

**結論:** `value_bet`で回収率が`top1_tansho`を下回る最大の原因は、**3着以内確率を1着確率として扱い、不適切な線形正規化を適用している**こと。モデルの順序情報（どの馬が強いか）は正しくても、確率の絶対値が期待値ベースの判定に使えるレベルのキャリブレーションになっていない。
